Pods:
"""""
An index is made up of pods, which are units of cloud resources (vCPU, RAM, disk) that provide storage and compute for each index.

Types of pods:
""""""""""""""
1) p1 - performance-optimized pods which provide very low query latencies, but hold fewer vectors per pod than s1 pods
2) s1 - optimized for storage and provide large storage capacity and lower overall costs with slightly higher query latencies than p1 pods
3) p2 - provides greater query throughput with lower latency. They support 200 QPS per replica and return queries in less than 10ms. This means that query throughput and latency are better than s1 and p1, especially for low dimension vectors (<512D)

For more details about storage capacity, please refer the below link:

https://docs.pinecone.io/docs/choosing-index-type-and-size#dimensionality-of-vectors

Query Per Second (QPS) and Adding Replicas:
"""""""""""""""""""""""""""""""""""""""""""
QPS speeds are governed by a combination of the pod type of the index and the number of replicas.

Each replica duplicates the resources and data in an index. This means that adding additional replicas increases the throughput of the index but not its capacity. However, adding replicas does not require downtime.

Throughput in terms of queries per second (QPS) scales linearly with the number of replicas per index.

Adding Pods:
""""""""""""
Adding pods to an index increases all resources (vCPU, RAM, Storage), including available capacity. We can add pods to the index without any downtime using vertical scaling.

For more details, refer the below link:

https://docs.pinecone.io/docs/scaling-indexes#vertical-scaling

Creating Namespaces for each community Vs Creating indexes for each community:
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Creating a new index for each community is extremely inefficient since for each index we need to add atleast one pods and if the indexes are underused by some community, it'll be a wastage of resources and cost.

So using the namespace approach is the optimal solution, pinecone allows us to partition the vectors in an index into namespaces, then we can assign a single namespace to a single community.

This way queries and other operations are then limited to one namespace or community, so different requests can search different subsets of our index.

Performance impact on metadata filtering:
"""""""""""""""""""""""""""""""""""""""""
Storing a metadata for each vector will impact both storage and performance.

If we have millions of vectors and if each vector have a metadata, this will consume a huge amount of storage.

Also, querying the index with metadata filtering will have a increase in latencies compared to the query without metadata.
